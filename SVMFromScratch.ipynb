{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"9b8c476a-7eb9-4649-aaf3-2bf6036b7669","_uuid":"682acb75-113d-40a6-978d-a751d39f2aa1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","train=pd.read_csv(\"/Users/saksham/Desktop/train.csv\")\n","xTest=pd.read_csv(\"/Users/saksham/Desktop/test.csv\")\n","yTrain=np.array(train[\"label\"])\n","xTrain=np.array(train.drop([\"label\"],axis=1))\n","def unpickle(file):\n","    import pickle\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","a=unpickle(\"/Users/saksham/Desktop/cifar-10-batches-py/test_batch\")\n","y=np.array(a)\n","yTest=np.array(a[b'labels'])\n","meanImage = (np.mean(xTrain, axis=0)).astype(int)\n","xTrain -= meanImage\n","xTest -= meanImage\n","\n","# Reshape data from channel to rows\n","xTrain = np.reshape(xTrain, (xTrain.shape[0], -1))\n","xTest = np.reshape(xTest, (xTest.shape[0], -1))\n","\n","# Add bias dimension columns\n","xTrain = np.hstack([xTrain, np.ones((xTrain.shape[0], 1))])\n","xTest = np.hstack([xTest, np.ones((xTest.shape[0], 1))])\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Start training Svm classifier\n"]}],"source":["\n","class Svm (object):\n","\n","    def __init__ (self, inputDim, outputDim):\n","        self.W = None\n","\n","        sigma =0.01\n","        self.W = sigma * np.random.randn(inputDim,outputDim)\n","\n","\n","    def calLoss (self, x, y, reg):\n","\n","        loss = 0.0\n","        dW = np.zeros_like(self.W)\n","\n","        s = x.dot(self.W)\n","        #Score with yi\n","        s_yi = s[np.arange(x.shape[0]),y]\n","        #finding the delta\n","        delta = s- s_yi[:,np.newaxis]+1\n","        #loss for samples\n","        loss_i = np.maximum(0,delta)\n","        loss_i[np.arange(x.shape[0]),y]=0\n","        loss = np.sum(loss_i)/x.shape[0]\n","        #Loss with regularization\n","        loss += reg*np.sum(self.W*self.W)\n","        #Calculating ds\n","        ds = np.zeros_like(delta)\n","        ds[delta > 0] = 1\n","        ds[np.arange(x.shape[0]),y] = 0\n","        ds[np.arange(x.shape[0]),y] = -np.sum(ds, axis=1)\n","\n","        dW = (1/x.shape[0]) * (x.T).dot(ds)\n","        dW = dW + (2* reg* self.W)\n","        return loss, dW\n","\n","    def train (self, x, y, lr=1e-3, reg=1e-5, iter=100, batchSize=10000):\n","\n","\n","        lossHistory = []\n","        for i in range(iter):\n","            xBatch = None\n","            yBatch = None\n","\n","            num_train = np.random.choice(x.shape[0], batchSize)\n","            xBatch = x[num_train]\n","            yBatch = y[num_train]\n","            loss, dW = self.calLoss(xBatch,yBatch,reg)\n","            self.W= self.W - lr * dW\n","            lossHistory.append(loss)\n","\n","            if  i % 1 == 0 and len(lossHistory) != 0:\n","                print ('Loop {0} loss {1}'.format(i, lossHistory[i]))\n","\n","        return lossHistory\n","\n","    def predict (self, x,):\n","\n","        yPred = np.zeros(x.shape[0])\n","\n","        s = x.dot(self.W)\n","        yPred = np.argmax(s, axis=1)\n","\n","        return yPred\n","\n","\n","    def calAccuracy (self, x, y):\n","        acc = 0\n","\n","        yPred = self.predict(x)\n","        acc = np.mean(y == yPred)*100\n","\n","        return acc\n","numClasses = np.max(yTrain) + 1\n","\n","print ('Start training Svm classifier')\n","\n","classifier = Svm(xTrain.shape[1], numClasses)\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loop 0 loss 32.86206853584808\n","Loop 1 loss 24.838155352545208\n","Loop 2 loss 28.638004117765988\n","Loop 3 loss 28.138353578590625\n","Loop 4 loss 31.57027359476696\n","Loop 5 loss 26.12409295439484\n","Loop 6 loss 30.392932813817637\n","Loop 7 loss 26.91275674178345\n","Loop 8 loss 31.256582493298605\n","Loop 9 loss 26.831303272368697\n","Loop 10 loss 30.698643063005772\n","Loop 11 loss 25.49674370852607\n","Loop 12 loss 31.03425702069514\n","Loop 13 loss 25.97774484899118\n","Loop 14 loss 31.3341205278846\n","Loop 15 loss 27.909085089516235\n","Loop 16 loss 31.333796431591583\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39m# Training classifier\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000002?line=1'>2</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mtrain(xTrain, yTrain, lr\u001b[39m=\u001b[39;49m\u001b[39m5e-6\u001b[39;49m, reg\u001b[39m=\u001b[39;49m\u001b[39m5e4\u001b[39;49m, \u001b[39miter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mTraining acc:   \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(classifier\u001b[39m.\u001b[39mcalAccuracy(xTrain, yTrain)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000002?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mTesting acc:    \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(classifier\u001b[39m.\u001b[39mcalAccuracy(xTest, yTest)))\n","\u001b[1;32m/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb Cell 2'\u001b[0m in \u001b[0;36mSvm.train\u001b[0;34m(self, x, y, lr, reg, iter, batchSize)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000001?line=41'>42</a>\u001b[0m yBatch \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000001?line=43'>44</a>\u001b[0m num_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], batchSize)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000001?line=44'>45</a>\u001b[0m xBatch \u001b[39m=\u001b[39m x[num_train]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000001?line=45'>46</a>\u001b[0m yBatch \u001b[39m=\u001b[39m y[num_train]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saksham/Desktop/zaiyan-svm-with-cifar-10.ipynb#ch0000001?line=46'>47</a>\u001b[0m loss, dW \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalLoss(xBatch,yBatch,reg)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Training classifier\n","classifier.train(xTrain, yTrain, lr=5e-7, reg=5e4, iter=100)\n","print ('Training acc:   {0}%'.format(classifier.calAccuracy(xTrain, yTrain)))\n","print ('Testing acc:    {0}%'.format(classifier.calAccuracy(xTest, yTest)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":4}
